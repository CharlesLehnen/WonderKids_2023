```{r}

rm(list = ls())

```

```{r}

library(dplyr)
library(ggplot2)
library(readr)
library(tidyr)
library(tm)
library(wordcloud)
library(ggwordcloud)
library(wesanderson)
library(stringr)
library(readr)
library(gt)
library(conflicted)

```

```{r}

data_raw <- read_csv(file = "../data/2023_Fall_Speaker_Survey.csv")

head(data_raw)

```

```{r}


# Create a lookup table for the original column names and their shortened names
question_lookup <- data.frame(
  Original_Column = colnames(data_raw),
  Shortened_Column = c(
    "Timestamp",                # 1
    "Name",                     # 2
    "Subject",                  # 3
    "Speaker_Before",           # 4
    "Overall_Rating",           # 5
    "Inspire_Info",             # 6
    "Hands_On_Activities",      # 7
    "Background_Knowledge",     # 8
    "Engagement_Enjoyment",     # 9
    "Staff_Helpfulness",        # 10
    "Went_Well",                # 11
    "Went_Not_Well",            # 12
    "Speaker_Quote",            # 13
    "Future_Suggestions",       # 14
    "Email"                     # 15
  )
)

# Rename columns in the data to use the shortened names
data <- data_raw %>%
  rename_with(~ question_lookup$Shortened_Column[match(., question_lookup$Original_Column)])

# Check the transformed data
head(data)


```

```{r}

# Word Cloud

# Reference relevant columns
relevant_columns <- data[, c(6, 7, 11, 13)] 

# Combine text data from the relevant columns
text_data <- apply(relevant_columns, 1, paste, collapse = " ")

# Create a text corpus
corpus <- Corpus(VectorSource(text_data))

# Define additional stopwords to remove
custom_stopwords <- c("andrea", "charles")

# Combine with default English stopwords
all_stopwords <- c(stopwords("english"), custom_stopwords)

# Preprocess the text data
corpus <- tm_map(corpus, content_transformer(tolower))  # Convert to lowercase
corpus <- tm_map(corpus, removePunctuation)            # Remove punctuation
corpus <- tm_map(corpus, removeNumbers)                # Remove numbers
corpus <- tm_map(corpus, removeWords, all_stopwords)   # Remove common + custom stopwords

# Create a Term Document Matrix
tdm <- TermDocumentMatrix(corpus)

# Convert TDM to matrix and compute word frequencies
m <- as.matrix(tdm)
word_freq <- sort(rowSums(m), decreasing = TRUE)
word_freq_df <- data.frame(word = names(word_freq), freq = word_freq)

# Create the Word Cloud using ggwordcloud
ggplot(word_freq_df, aes(label = word, size = freq)) +
  geom_text_wordcloud() +
  labs(title = "Word Cloud of Speaker Feedback") +
  theme_minimal()

# Save the Word Cloud
ggsave("../outputs/word_cloud.png", width = 8, height = 6)



```

```{r}


# Scale responses for comparability
data <- data %>%
  mutate(
    Background_Knowledge = Background_Knowledge * 2,
    Engagement_Enjoyment = Engagement_Enjoyment * 2,
    Staff_Helpfulness = Staff_Helpfulness * 2
  )

# Calculate summary statistics
summary_table <- data %>%
  select(Overall_Rating, Background_Knowledge, Engagement_Enjoyment, Staff_Helpfulness) %>%
  pivot_longer(cols = everything(), names_to = "Question", values_to = "Response") %>%
  group_by(Question) %>%
  summarize(
    Mean = mean(Response, na.rm = TRUE),
    SD = sd(Response, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  )

# Create a formatted table using gt
formatted_table <- summary_table %>%
  gt() %>%
  tab_header(
    title = "Lesson Ratings by Question",
    subtitle = "Fall 2023 Speaker Feedback"
  ) %>%
  cols_label(
    Question = "Survey Question",
    Mean = "Mean Response",
    SD = "Standard Deviation",
    n = "Sample Size (n)"
  ) %>%
  tab_spanner(
    label = "Response Summary",
    columns = c(Mean, SD, n)
  ) %>%
  fmt_number(
    columns = c(Mean, SD),
    decimals = 2
  ) %>%
  tab_footnote(
    footnote = "Mean and Standard Deviation calculated from speaker feedback responses. Scaled to a maximum of 10.",
    locations = cells_column_labels(columns = c(Mean, SD))
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_spanners()
  ) %>%
  tab_options(
    table.font.size = 12,
    column_labels.font.size = 14
  )

# Print the table
formatted_table



```

```{r}

# Load necessary libraries
library(tidyverse)

# Load the dataset
data <- read_csv("../data/pre_post_test_scores_spring_2023_fall_2023.csv", show_col_types = FALSE)

# Rename columns for clarity
data <- data %>%
  rename(
    Semester = `Semester`,
    Test_Type = `Test Type`,
    STEM_Topic = `STEM Topic`,
    Class = `Class`,
    Total_Students = `Total Students`,
    Correct = `# correct`,
    Percent = `%`
  )

# Convert "N/A" to NA
data[data == "N/A"] <- NA

# Convert necessary columns to numeric
data <- data %>%
  mutate(
    Total_Students = as.numeric(Total_Students),
    Correct = as.numeric(Correct),
    Percent = as.numeric(Percent)
  )

# Filter for Fall 2023
fall_2023_data <- data %>% filter(Semester == "Fall 2023")

# Reshape data: pivot pre-test and post-test scores into separate columns
fall_2023_wide <- fall_2023_data %>%
  select(Semester, Class, STEM_Topic, Test_Type, Percent) %>%
  pivot_wider(names_from = Test_Type, values_from = Percent, names_prefix = "Test_") %>%
  rename(Test_Pre = `Test_Pre-Test`, Test_Post = `Test_Post-Test`) %>% # Rename problematic columns
  drop_na()  # Remove any rows with NA values

# Check column names to ensure correct pivoting
print("Column names after pivoting:")
print(colnames(fall_2023_wide))

# Print **median** values for each test type
median_values <- fall_2023_data %>%
  group_by(Class, Test_Type) %>%
  summarize(Median_Score = median(Percent, na.rm = TRUE), .groups = "drop")

print("Median Values for Pre-Test and Post-Test:")
print(median_values)

# Perform paired t-tests for K-2 and 3-5
if ("Test_Pre" %in% colnames(fall_2023_wide) & "Test_Post" %in% colnames(fall_2023_wide)) {
  t_test_k2 <- t.test(fall_2023_wide$Test_Pre[fall_2023_wide$Class == "K-2"],
                      fall_2023_wide$Test_Post[fall_2023_wide$Class == "K-2"],
                      paired = TRUE, na.action = na.omit)

  t_test_35 <- t.test(fall_2023_wide$Test_Pre[fall_2023_wide$Class == "3-5"],
                      fall_2023_wide$Test_Post[fall_2023_wide$Class == "3-5"],
                      paired = TRUE, na.action = na.omit)

  # Print t-test results
  print("T-Test Results for K-2:")
  print(t_test_k2)

  print("T-Test Results for 3-5:")
  print(t_test_35)
} else {
  print("Error: Pre-Test or Post-Test columns are missing. Check pivot_wider().")
}

# Plot the data
ggplot(fall_2023_data, aes(x = Test_Type, y = Percent, fill = Test_Type)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(alpha = 0.3, width = 0.2) +
  facet_wrap(~ Class) +
  labs(
    title = "Fall 2023 Pre-Test vs. Post-Test Percentages",
    x = "Test Type",
    y = "Percent (%)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

# Save the plot
ggsave("../outputs/fall_2023_pre_post_test_comparison.png", width = 7.29, height = 4.5, dpi = 300)



```

```{r}

# Combine K-5 by removing Class column
data_k5 <- data %>%
  filter(Semester == "Fall 2023") %>%  # Ensure we're analyzing Fall 2023
  select(Test_Type, Percent) %>%
  mutate(Test_Type = factor(Test_Type, levels = c("Pre-Test", "Post-Test")))

# Compute median values for each test type
median_values <- data_k5 %>%
  group_by(Test_Type) %>%
  summarize(Median_Score = median(Percent, na.rm = TRUE), .groups = "drop")

# Print median values
print("Median Values for Pre-Test and Post-Test:")
print(median_values)

# Perform Student's t-test (Unpaired Two-Sample t-test)
pre_test_scores <- data_k5 %>% filter(Test_Type == "Pre-Test") %>% pull(Percent)
post_test_scores <- data_k5 %>% filter(Test_Type == "Post-Test") %>% pull(Percent)

t_test_results <- t.test(pre_test_scores, post_test_scores, paired = FALSE, var.equal = TRUE)

# Print results in ANOVA-like format
anova_format <- data.frame(
  Source = "Test_Type",
  DF = round(t_test_results$parameter, 2),
  `Sum Sq` = NA,  # Not available for t-test
  `Mean Sq` = NA, # Not available for t-test
  F = NA,         # F-statistic not applicable for t-test
  t = round(t_test_results$statistic, 3),   # t-statistic
  p = round(t_test_results$p.value, 5)  # p-value
)

# Print results
print(anova_format)

# Plot the data (Boxplot and Jitter)
ggplot(data_k5, aes(x = Test_Type, y = Percent, fill = Test_Type)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(alpha = 0.3, width = 0.2) +
  labs(
    title = "Pre-Test vs. Post-Test Percentages (K-5, Fall 2023)",
    x = "Test Type",
    y = "Percent (%)"
  ) +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

# Save the plot
ggsave("../outputs/k5_pre_post_test_comparison.png", width = 7.29, height = 4.5, dpi = 300)




```

```{r}

# Box and Whisker Plot (Jittered)


# Separate pre and post-tests
pre_tests <- data %>% filter(Test_Type == "Pre-Test")
post_tests <- data %>% filter(Test_Type == "Post-Test")

# Join pre and post-tests
improvement_data <- pre_tests %>%
  rename(Pre_Total_Students = Total_Students, Pre_Correct = Correct, Pre_Percent = Percent) %>%
  left_join(post_tests %>%
              rename(Post_Total_Students = Total_Students, Post_Correct = Correct, Post_Percent = Percent),
            by = c("Semester", "STEM_Topic", "Class"))

# Calculate improvement and remove NA values
improvement_data <- improvement_data %>%
  mutate(Improvement = as.numeric(Post_Percent) - as.numeric(Pre_Percent)) %>%
  select(Semester, Class, Improvement) %>%
  drop_na()

# Convert Semester into an ordered factor to control display order
improvement_data$Semester <- factor(improvement_data$Semester, levels = c("Spring 2023", "Fall 2023"))

# Plot the overall improvement, faceted by Class (K-2 and 3-5)
ggplot(improvement_data, aes(x = Semester, y = Improvement, fill = Semester)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(alpha = 0.3, width = 0.2) +
  facet_wrap(~ Class) +
  labs(
    title = "Overall Improvement from Pre to Post Test by Semester and Group",
    x = "Semester",
    y = "Improvement (%)"
  ) +
  theme(legend.position = "none")

# Save the plot
ggsave("../outputs/faceted_pre_post_test_improvement.png", width = 7.29, height = 4.5, dpi = 300)



```

```{r}

# Load the dataset
data <- read_csv("../data/favorite_activities_fall_2023.csv", show_col_types = FALSE)

# Calculate total votes per activity & standard deviation
data_summary <- data %>%
  group_by(Activity, Topic) %>%
  summarize(
    Total_Votes = sum(Votes, na.rm = TRUE),
    SD_Votes = sd(Votes, na.rm = TRUE),  # Standard deviation for error bars
    .groups = "drop"
  ) %>%
  mutate(Percent_Votes = (Total_Votes / sum(Total_Votes)) * 100,
         SD_Percent = (SD_Votes / sum(Total_Votes)) * 100)  # Convert to percentage

# Define color palette based on topics
topic_colors <- wes_palette("Darjeeling1", n = length(unique(data_summary$Topic)), type = "continuous")

# Create the bar plot with colors by topic & error bars extending only to the right
ggplot(data_summary, aes(x = reorder(Activity, Percent_Votes), y = Percent_Votes, fill = Topic)) +
  geom_bar(stat = "identity", width = 0.7) +
  geom_errorbar(aes(ymin = Percent_Votes, ymax = Percent_Votes + SD_Percent), width = 0.2) +  # Error bars extend only to the right
  coord_flip() +
  scale_fill_manual(values = topic_colors) +
  labs(
    title = "Favorite Activities for K-5",
    x = "Activity",
    y = "Percentage of Total Votes"
  ) +
  theme_minimal() +
  theme(legend.position = "none")  # Remove legend

# Save the plot
ggsave("../outputs/favorite_activities_by_topic_k5.png", width = 8, height = 6, dpi = 300)

    


```

```{r}

# Perform ANOVA
anova_result <- aov(Votes ~ Activity, data = data)
summary(anova_result)

# Perform Tukey HSD test
tukey_result <- TukeyHSD(anova_result)

# Print Tukey HSD results
print(tukey_result)

# Plot
plot(tukey_result)


```

```{r}


# Load the dataset
data <- read_csv("../data/favorite_topics_fall_2023.csv", show_col_types = FALSE)

# Compute percentages for the donut chart
data <- data %>%
  mutate(
    Fraction = Votes / sum(Votes),
    ymax = cumsum(Fraction),
    ymin = c(0, head(ymax, -1)),
    LabelPosition = (ymax + ymin) / 2,
    Label = paste0(str_wrap(Topic, width = 12), "\n", round(Fraction * 100, 1), "%")  # Wrapped text
  )

# ANOVA test to compare votes across topics
anova_results <- aov(Votes ~ Topic, data = data)
anova_summary <- summary(anova_results)

# Print ANOVA results
print("ANOVA Results for Favorite Topics:")
print(anova_summary)

# Plot the donut chart
ggplot(data, aes(ymax = ymax, ymin = ymin, xmax = 4, xmin = 3, fill = Topic)) +
  geom_rect(color = "white") +
  geom_text(aes(x = 3.5, y = LabelPosition, label = str_wrap(Label, width = 10)), 
            size = 3) + 
  scale_fill_manual(values = wes_palette("Darjeeling1", n = nrow(data), type = "continuous")) + # Chosen bc Darjeeling1 is colorblind friendly
  coord_polar(theta = "y") +
  xlim(c(2, 4)) +  # Controls thickness of the donut
  theme_void() +
  theme(
    legend.position = "none",
    plot.title = element_text(size = 14, hjust = 0.5)
  ) +
  labs(title = "Favorite Topics for K-5")

# Save the plot
ggsave("../outputs/favorite_topics_k5.png", width = 8, height = 6, dpi = 300)



```

```{r}

# Load the dataset
attendance <- read_csv("../data/fall_2023_attendance.csv", show_col_types = FALSE)

# Calculate percentage attendance
attendance <- attendance %>%
  mutate(Percent_Attended = (Attended / Total_lessons) * 100) %>%
  filter(!is.na(Percent_Attended))

# Summary statistics by grade
attendance_summary <- attendance %>%
  group_by(Grade) %>%
  summarize(
    Avg_Attended = mean(Attended, na.rm = TRUE),
    Avg_Percent = mean(Percent_Attended, na.rm = TRUE),
    SD_Attended = sd(Attended, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  )

# Order the grades to ensure Kindergarten appears first
attendance$Grade <- factor(attendance$Grade, levels = c("Kindergarten", "1st", "2nd", "3rd", "4th", "5th", "6th"))

# Define color palette (Remove black from Okabe-Ito)
okabe_ito_colors <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")  # Excluding black

# Boxplot of attendance by grade
ggplot(attendance, aes(x = Grade, y = Percent_Attended, fill = Grade)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(alpha = 0.4, color = "gray30", width = 0.2) +  # Use dark gray for better visibility
  scale_fill_manual(values = okabe_ito_colors) +
  labs(
    title = "Attendance Distribution by Grade",
    x = "Grade",
    y = "Attendance (%)"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Bar plot of average attendance by grade
ggplot(attendance_summary, aes(x = Grade, y = Avg_Percent, fill = Grade)) +
  geom_bar(stat = "identity", width = 0.7) +
  scale_fill_manual(values = okabe_ito_colors) +
  geom_errorbar(
    aes(ymin = Avg_Percent - SD_Attended, ymax = Avg_Percent + SD_Attended),
    width = 0.2
  ) +
  labs(
    title = "Average Attendance by Grade",
    x = "Grade",
    y = "Average Attendance (%)"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Create a formatted table using gt
attendance_table <- attendance_summary %>%
  gt() %>%
  tab_header(
    title = "Attendance Summary by Grade",
    subtitle = "Fall 2023 Attendance Data"
  ) %>%
  cols_label(
    Grade = "Grade",
    Avg_Attended = "Avg. Lessons Attended",
    Avg_Percent = "Avg. Attendance (%)",
    SD_Attended = "Standard Deviation",
    n = "Sample Size (n)"
  ) %>%
  tab_spanner(
    label = "Attendance Metrics",
    columns = c(Avg_Attended, Avg_Percent, SD_Attended)
  ) %>%
  fmt_number(
    columns = c(Avg_Attended, Avg_Percent, SD_Attended),
    decimals = 2
  ) %>%
  tab_footnote(
    footnote = "Percentages and averages calculated based on total lessons attended.",
    locations = cells_column_labels(columns = Avg_Percent)
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_spanners()
  ) %>%
  tab_options(
    table.font.size = 12,
    column_labels.font.size = 14
  )

# Print the table
attendance_table




```

```{r}

# Perform ANOVA
attendanceANOVA <- lm(Percent_Attended ~ Grade, data = attendance)
anova_results <- anova(attendanceANOVA)

# Print
print("ANOVA Results:")
print(anova_results)

# Tukey's Honest Significant Difference test
tukey_results <- TukeyHSD(aov(attendanceANOVA))

# Print
print("Tukey HSD Results:")
print(tukey_results)

# Plot
plot(tukey_results, las = 1)


```

```{r}


# Read in the attendance dataset
attendance_full <- read_csv("../data/attendance_full.csv", show_col_types = FALSE)

# Convert wide format to long format (pivot attendance data)
attendance_long <- attendance_full %>%
  pivot_longer(cols = -c(Grade, Student), names_to = "Date", values_to = "Attended")

# Convert TRUE/FALSE attendance values to numeric (1 = attended, 0 = absent)
attendance_long <- attendance_long %>%
  mutate(
    Attended = as.numeric(Attended), 
    Date = as.Date(Date, format = "%m/%d")  # Convert to Date format
  )

# Ensure that Date conversion worked
print(unique(attendance_long$Date))  # Check the unique dates

# If Date is not in the correct format, try:
attendance_long <- attendance_long %>%
  mutate(Date = as.Date(Date, format = "%m/%d", origin = "2023-01-01"))

# Calculate cumulative attendance decline over time
attendance_summary <- attendance_long %>%
  group_by(Date) %>%
  summarize(
    Attendance_Rate = mean(Attended, na.rm = TRUE) * 100  # Convert proportion to percentage
  ) %>%
  arrange(Date) %>%  # Ensure correct chronological order
  mutate(
    Attendance_Change = c(NA, diff(Attendance_Rate)),  # Compute rate of attendance change
    Cumulative_Decline = 100 - Attendance_Rate  # Track cumulative decline
  )


# Plot attendance trends over time (Original trend)
p1 <- ggplot(attendance_summary, aes(x = Date, y = Attendance_Rate)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Attendance Trends Over Time",
    x = "Date",
    y = "Attendance Rate (%)"
  ) 

p1

# Plot rate of change of attendance (How quickly students are leaving)
p2 <- ggplot(attendance_summary, aes(x = Date, y = Attendance_Change)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +  # Reference line for no change
  labs(
    title = "Rate of Change in Attendance Over Time",
    x = "Date",
    y = "Change in Attendance Rate (%)"
  ) 

p2

# Save the plots
ggsave("../outputs/attendance_trends_over_time.png", plot = p1, width = 7.5, height = 5, dpi = 300)
ggsave("../outputs/attendance_rate_of_change.png", plot = p2, width = 7.5, height = 5, dpi = 300)



```

```{r}

# Calculate overall attendance rate
overall_attendance_rate <- attendance_long %>%
  summarize(Overall_Attendance_Rate = mean(Attended, na.rm = TRUE) * 100) %>%
  pull(Overall_Attendance_Rate)

# Print the overall attendance rate
print(paste("Overall Attendance Rate:", round(overall_attendance_rate, 2), "%"))


```
