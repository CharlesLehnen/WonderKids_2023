```{r}

rm(list = ls())

```

```{r}

library(dplyr)
library(ggplot2)
library(readr)
library(tidyr)
library(tm)
library(wordcloud)
library(ggwordcloud)
library(wesanderson)
library(stringr)
library(readr)
library(gt)


```

```{r}

data_raw <- read_csv(file = "../data/2023_Fall_Speaker_Survey.csv")

head(data_raw)

```

```{r}


# Create a lookup table for the original column names and their shortened names
question_lookup <- data.frame(
  Original_Column = colnames(data_raw),
  Shortened_Column = c(
    "Timestamp",                # 1
    "Name",                     # 2
    "Subject",                  # 3
    "Speaker_Before",           # 4
    "Overall_Rating",           # 5
    "Inspire_Info",             # 6
    "Hands_On_Activities",      # 7
    "Background_Knowledge",     # 8
    "Engagement_Enjoyment",     # 9
    "Staff_Helpfulness",        # 10
    "Went_Well",                # 11
    "Went_Not_Well",            # 12
    "Speaker_Quote",            # 13
    "Future_Suggestions",       # 14
    "Email"                     # 15
  )
)

# Rename columns in the data to use the shortened names
data <- data_raw %>%
  rename_with(~ question_lookup$Shortened_Column[match(., question_lookup$Original_Column)])

# Check the transformed data
head(data)


```

```{r}

# Word Cloud

# Reference relevant columns
relevant_columns <- data[, c(6, 7, 11, 13)] 

# Combine text data from the relevant columns
text_data <- apply(relevant_columns, 1, paste, collapse = " ")

# Create a text corpus
corpus <- Corpus(VectorSource(text_data))

# Define additional stopwords to remove
custom_stopwords <- c("andrea", "charles")

# Combine with default English stopwords
all_stopwords <- c(stopwords("english"), custom_stopwords)

# Preprocess the text data
corpus <- tm_map(corpus, content_transformer(tolower))  # Convert to lowercase
corpus <- tm_map(corpus, removePunctuation)            # Remove punctuation
corpus <- tm_map(corpus, removeNumbers)                # Remove numbers
corpus <- tm_map(corpus, removeWords, all_stopwords)   # Remove common + custom stopwords

# Create a Term Document Matrix
tdm <- TermDocumentMatrix(corpus)

# Convert TDM to matrix and compute word frequencies
m <- as.matrix(tdm)
word_freq <- sort(rowSums(m), decreasing = TRUE)
word_freq_df <- data.frame(word = names(word_freq), freq = word_freq)

# Create the Word Cloud using ggwordcloud
ggplot(word_freq_df, aes(label = word, size = freq)) +
  geom_text_wordcloud() +
  labs(title = "Word Cloud of Speaker Feedback") +
  theme_minimal()

# Save the Word Cloud
ggsave("../outputs/word_cloud.png", width = 8, height = 6)



```

```{r}


# Scale responses for comparability
data <- data %>%
  mutate(
    Background_Knowledge = Background_Knowledge * 2,
    Engagement_Enjoyment = Engagement_Enjoyment * 2,
    Staff_Helpfulness = Staff_Helpfulness * 2
  )

# Calculate summary statistics
summary_table <- data %>%
  select(Overall_Rating, Background_Knowledge, Engagement_Enjoyment, Staff_Helpfulness) %>%
  pivot_longer(cols = everything(), names_to = "Question", values_to = "Response") %>%
  group_by(Question) %>%
  summarize(
    Mean = mean(Response, na.rm = TRUE),
    SD = sd(Response, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  )

# Create a formatted table using gt
formatted_table <- summary_table %>%
  gt() %>%
  tab_header(
    title = "Lesson Ratings by Question",
    subtitle = "Fall 2023 Speaker Feedback"
  ) %>%
  cols_label(
    Question = "Survey Question",
    Mean = "Mean Response",
    SD = "Standard Deviation",
    n = "Sample Size (n)"
  ) %>%
  tab_spanner(
    label = "Response Summary",
    columns = c(Mean, SD, n)
  ) %>%
  fmt_number(
    columns = c(Mean, SD),
    decimals = 2
  ) %>%
  tab_footnote(
    footnote = "Mean and Standard Deviation calculated from speaker feedback responses. Scaled to a maximum of 10.",
    locations = cells_column_labels(columns = c(Mean, SD))
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_spanners()
  ) %>%
  tab_options(
    table.font.size = 12,
    column_labels.font.size = 14
  )

# Print the table
formatted_table



```


```{r}

# Load the dataset
data <- read_csv("../data/pre_post_test_scores_spring_2023_fall_2023.csv", show_col_types = FALSE)

# Rename columns for clarity
data <- data %>%
  rename(
    Semester = `Semester`,
    Test_Type = `Test Type`,
    STEM_Topic = `STEM Topic`,
    Class = `Class`,
    Total_Students = `Total Students`,
    Correct = `# correct`,
    Percent = `%`
  )

# Convert N/A to NA
data[data == "N/A"] <- NA

# Convert necessary columns to numeric
data <- data %>%
  mutate(
    Total_Students = as.numeric(Total_Students),
    Correct = as.numeric(Correct),
    Percent = as.numeric(Percent)
  )

# Filter for Fall 2023
fall_2023_data <- data %>% filter(Semester == "Fall 2023")

# Combine pre- and post-test data for Fall 2023
fall_2023_plot_data <- fall_2023_data %>%
  select(Test_Type, Class, Percent) %>%
  mutate(Test_Type = factor(Test_Type, levels = c("Pre-Test", "Post-Test")))

# Plot the data
ggplot(fall_2023_plot_data, aes(x = Test_Type, y = Percent, fill = Test_Type)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(alpha = 0.3, width = 0.2, aes(color = Test_Type)) +
  facet_wrap(~ Class) +
  labs(
    title = "Fall 2023 Pre-Test vs. Post-Test Percentages",
    x = "Test Type",
    y = "Percent (%)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

# Save the plot
ggsave("../outputs/fall_2023_pre_post_test_comparison.png", width = 7.29, height = 4.5, dpi = 300)




```


```{r}

# Box and Whisker Plot (Jittered)


# Separate pre and post-tests
pre_tests <- data %>% filter(Test_Type == "Pre-Test")
post_tests <- data %>% filter(Test_Type == "Post-Test")

# Join pre and post-tests
improvement_data <- pre_tests %>%
  rename(Pre_Total_Students = Total_Students, Pre_Correct = Correct, Pre_Percent = Percent) %>%
  left_join(post_tests %>%
              rename(Post_Total_Students = Total_Students, Post_Correct = Correct, Post_Percent = Percent),
            by = c("Semester", "STEM_Topic", "Class"))

# Calculate improvement and remove NA values
improvement_data <- improvement_data %>%
  mutate(Improvement = as.numeric(Post_Percent) - as.numeric(Pre_Percent)) %>%
  select(Semester, Class, Improvement) %>%
  drop_na()

# Convert Semester into an ordered factor to control display order
improvement_data$Semester <- factor(improvement_data$Semester, levels = c("Spring 2023", "Fall 2023"))

# Plot the overall improvement, faceted by Class (K-2 and 3-5)
ggplot(improvement_data, aes(x = Semester, y = Improvement, fill = Semester)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(alpha = 0.3, width = 0.2) +
  facet_wrap(~ Class) +
  labs(
    title = "Overall Improvement from Pre to Post Test by Semester and Class",
    x = "Semester",
    y = "Improvement (%)"
  ) +
  theme(legend.position = "none")

# Save the plot
ggsave("../outputs/faceted_pre_post_test_improvement.png", width = 7.29, height = 4.5, dpi = 300)



```


```{r}


data <- read_csv("../data/favorite_activities_fall_2023.csv")

# Calculate mean and standard deviation for each activity across K-2 and 3-5
data_summary <- data %>%
  group_by(Activity) %>%
  summarize(
    Mean = mean(Votes),
    SD = sd(Votes),
    .groups = "drop"
  )

# Create the bar plot with error bars extending only upwards
ggplot(data_summary, aes(x = reorder(Activity, Mean), y = Mean)) +
  geom_bar(stat = "identity", width = 0.7) +
  geom_errorbar(aes(ymin = Mean, ymax = Mean + SD), width = 0.2) +  # Error bars only extend upwards
  coord_flip() +
  labs(
    title = "Favorite Activities for Grades K-5",
    x = "Activity",
    y = "Mean Votes")
    


```

```{r}

data <- read_csv("../data/favorite_topics_fall_2023.csv")

# Compute percentages for the donut chart
data <- data %>%
  mutate(
    Fraction = Votes / sum(Votes),
    ymax = cumsum(Fraction),
    ymin = c(0, head(ymax, -1)),
    LabelPosition = (ymax + ymin) / 2,
    Label = paste0(str_wrap(Topic, width = 12), "\n", round(Fraction * 100, 1), "%")  # Wrapped text
  )

# Plot
ggplot(data, aes(ymax = ymax, ymin = ymin, xmax = 4, xmin = 3, fill = Topic)) +
  geom_rect(color = "white") +
  geom_text(aes(x = 3.5, y = LabelPosition, label = str_wrap(Label, width = 10)), 
            size = 3) + 
  scale_fill_manual(values = wes_palette("Darjeeling1", n = nrow(data), type = "continuous")) + # Chosen bc Darjeeling1 is colorblind friendly
  coord_polar(theta = "y") +
  xlim(c(2, 4)) +  # Controls thickness of the donut
  theme_void() +
  theme(
    legend.position = "none",
    plot.title = element_text(size = 14, hjust = 0.5)
  ) +
  labs(title = "Favorite Topics for K-5")


```


```{r}

# Load the dataset
attendance <- read_csv("../data/fall_2023_attendance.csv", show_col_types = FALSE)

# Calculate percentage attendance
attendance <- attendance %>%
  mutate(Percent_Attended = (Attended / Total_lessons) * 100) %>%
  filter(!is.na(Percent_Attended))

# Summary statistics by grade
attendance_summary <- attendance %>%
  group_by(Grade) %>%
  summarize(
    Avg_Attended = mean(Attended, na.rm = TRUE),
    Avg_Percent = mean(Percent_Attended, na.rm = TRUE),
    SD_Attended = sd(Attended, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  )

# Order the grades to ensure Kindergarten appears first
attendance$Grade <- factor(attendance$Grade, levels = c("Kindergarten", "1st", "2nd", "3rd", "4th", "5th", "6th"))

# Define color palette (Remove black from Okabe-Ito)
okabe_ito_colors <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")  # Excluding black

# Boxplot of attendance by grade
ggplot(attendance, aes(x = Grade, y = Percent_Attended, fill = Grade)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(alpha = 0.4, color = "gray30", width = 0.2) +  # Use dark gray for better visibility
  scale_fill_manual(values = okabe_ito_colors) +
  labs(
    title = "Attendance Distribution by Grade",
    x = "Grade",
    y = "Attendance (%)"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Bar plot of average attendance by grade
ggplot(attendance_summary, aes(x = Grade, y = Avg_Percent, fill = Grade)) +
  geom_bar(stat = "identity", width = 0.7) +
  scale_fill_manual(values = okabe_ito_colors) +
  geom_errorbar(
    aes(ymin = Avg_Percent - SD_Attended, ymax = Avg_Percent + SD_Attended),
    width = 0.2
  ) +
  labs(
    title = "Average Attendance by Grade",
    x = "Grade",
    y = "Average Attendance (%)"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Create a formatted table using gt
attendance_table <- attendance_summary %>%
  gt() %>%
  tab_header(
    title = "Attendance Summary by Grade",
    subtitle = "Fall 2023 Attendance Data"
  ) %>%
  cols_label(
    Grade = "Grade",
    Avg_Attended = "Avg. Lessons Attended",
    Avg_Percent = "Avg. Attendance (%)",
    SD_Attended = "Standard Deviation",
    n = "Sample Size (n)"
  ) %>%
  tab_spanner(
    label = "Attendance Metrics",
    columns = c(Avg_Attended, Avg_Percent, SD_Attended)
  ) %>%
  fmt_number(
    columns = c(Avg_Attended, Avg_Percent, SD_Attended),
    decimals = 2
  ) %>%
  tab_footnote(
    footnote = "Percentages and averages calculated based on total lessons attended.",
    locations = cells_column_labels(columns = Avg_Percent)
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_spanners()
  ) %>%
  tab_options(
    table.font.size = 12,
    column_labels.font.size = 14
  )

# Print the table
attendance_table




```
